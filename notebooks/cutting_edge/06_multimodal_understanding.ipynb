{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11.6: Multimodal Understanding\n\n**Goal**: Work with vision-language models and cross-modal understanding\n\n**Time**: 90 minutes\n\n**Concepts Covered**:\n- Vision-language model architecture\n- CLIP encoder integration\n- Cross-attention implementation\n- Image-text training pipeline\n- Edge deployment for VLM (MiniCPM-V, MobileVLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install torch transformers accelerate matplotlib seaborn numpy -q"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Vision-Language Model Architecture\nimport torch\nimport torch.nn as nn\n\nclass VisionLanguageModel(nn.Module):\n    \"\"\"Simple VLM architecture\"\"\"\n    def __init__(self, vision_dim=768, text_dim=768, hidden_dim=1024):\n        super().__init__()\n        \n        # Vision encoder (simulated - in practice use CLIP/ViT)\n        self.vision_encoder = nn.Sequential(\n            nn.Linear(224*224*3, vision_dim),  # Simplified\n            nn.LayerNorm(vision_dim),\n            nn.GELU(),\n        )\n        \n        # Text encoder\n        self.text_encoder = nn.Embedding(50000, text_dim)\n        \n        # Cross-attention\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=hidden_dim,\n            num_heads=8,\n            batch_first=True\n        )\n        \n        # Fusion layer\n        self.fusion = nn.Sequential(\n            nn.Linear(vision_dim + text_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.GELU(),\n        )\n        \n        # Language model head\n        self.lm_head = nn.Linear(hidden_dim, 50000)\n    \n    def forward(self, image, text_ids):\n        \"\"\"Forward pass with image and text\"\"\"\n        # Encode image\n        image_features = self.vision_encoder(image)\n        \n        # Encode text\n        text_features = self.text_encoder(text_ids)\n        \n        # Fuse features\n        fused = self.fusion(torch.cat([image_features, text_features], dim=-1))\n        \n        # Cross-attention\n        attn_out, _ = self.cross_attention(fused, fused, fused)\n        \n        # Language modeling\n        logits = self.lm_head(attn_out)\n        \n        return logits\n\nprint(\"Vision-Language Model:\")\nprint(\"- Vision encoder: processes images\")\nprint(\"- Text encoder: processes text\")\nprint(\"- Cross-attention: aligns modalities\")\nprint(\"- LM head: generates text\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CLIP-Style Contrastive Learning\ndef clip_loss(image_features, text_features, temperature=0.07):\n    \"\"\"CLIP contrastive loss\"\"\"\n    # Normalize features\n    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n    \n    # Compute similarity matrix\n    logits = torch.matmul(image_features, text_features.t()) / temperature\n    \n    # Labels: diagonal (matched pairs)\n    batch_size = image_features.shape[0]\n    labels = torch.arange(batch_size, device=image_features.device)\n    \n    # Cross-entropy loss (symmetric)\n    loss_img = nn.functional.cross_entropy(logits, labels)\n    loss_txt = nn.functional.cross_entropy(logits.t(), labels)\n    \n    return (loss_img + loss_txt) / 2\n\nprint(\"CLIP Contrastive Learning:\")\nprint(\"- Learn aligned image-text embeddings\")\nprint(\"- Maximize similarity for matched pairs\")\nprint(\"- Minimize similarity for unmatched pairs\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n\u2705 **Module Complete**\n\n## Next Steps\n\nContinue to the next module in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}