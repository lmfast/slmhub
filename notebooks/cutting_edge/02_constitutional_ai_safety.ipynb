{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 11.2: Constitutional AI & Safety\n\n**Goal**: Implement safety filters and constitutional AI workflow\n\n**Time**: 90 minutes\n\n**Concepts Covered**:\n- Constitutional AI workflow\n- Critique and revision pipeline\n- Safety filter implementation\n- Toxicity detection\n- PII detection\n- Prompt injection prevention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install torch transformers accelerate matplotlib seaborn numpy -q"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Constitutional AI Workflow\nclass ConstitutionalAI:\n    def __init__(self, model, constitution):\n        self.model = model\n        self.constitution = constitution  # List of principles\n    \n    def critique(self, response, prompt):\n        \"\"\"Critique response against constitution\"\"\"\n        critiques = []\n        \n        for principle in self.constitution:\n            critique_prompt = f\"\"\"\nPrinciple: {principle}\nResponse: {response}\nPrompt: {prompt}\n\nDoes the response violate this principle? Explain.\n\"\"\"\n            # Check if response violates principle\n            violation = self._check_violation(response, principle)\n            if violation:\n                critiques.append({\n                    \"principle\": principle,\n                    \"violation\": violation,\n                    \"severity\": \"high\"\n                })\n        \n        return critiques\n    \n    def revise(self, response, critiques):\n        \"\"\"Revise response based on critiques\"\"\"\n        if not critiques:\n            return response\n        \n        revision_prompt = f\"\"\"\nOriginal response: {response}\nCritiques: {critiques}\n\nPlease revise the response to address these critiques while maintaining helpfulness.\n\"\"\"\n        revised = self.model.generate(revision_prompt)\n        return revised\n    \n    def _check_violation(self, response, principle):\n        \"\"\"Check if response violates principle\"\"\"\n        # Simplified: check for keywords\n        # In production, use a safety classifier\n        return False\n\n# Example constitution\nconstitution = [\n    \"Be helpful, harmless, and honest\",\n    \"Do not generate harmful content\",\n    \"Respect privacy and confidentiality\",\n    \"Do not provide medical or legal advice\",\n]\n\nprint(\"Constitutional AI:\")\nprint(\"- Critiques responses against principles\")\nprint(\"- Revises responses to be safer\")\nprint(\"- Iterative improvement process\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Safety Filter Implementation\nimport re\nfrom typing import List, Dict\n\nclass SafetyFilter:\n    def __init__(self):\n        # Toxicity keywords (simplified)\n        self.toxicity_patterns = [\n            r\"\\b(kill|harm|violence)\\b\",\n            # Add more patterns\n        ]\n        \n        # PII patterns\n        self.pii_patterns = [\n            r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\",  # SSN\n            r\"\\b\\d{4}\\s?\\d{4}\\s?\\d{4}\\s?\\d{4}\\b\",  # Credit card\n            r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\",  # Email\n        ]\n    \n    def check_toxicity(self, text: str) -> Dict:\n        \"\"\"Check for toxic content\"\"\"\n        for pattern in self.toxicity_patterns:\n            if re.search(pattern, text, re.IGNORECASE):\n                return {\n                    \"is_toxic\": True,\n                    \"reason\": f\"Matched pattern: {pattern}\",\n                    \"severity\": \"high\"\n                }\n        return {\"is_toxic\": False}\n    \n    def detect_pii(self, text: str) -> List[Dict]:\n        \"\"\"Detect personally identifiable information\"\"\"\n        pii_found = []\n        \n        for pattern in self.pii_patterns:\n            matches = re.findall(pattern, text)\n            if matches:\n                pii_found.append({\n                    \"type\": self._get_pii_type(pattern),\n                    \"matches\": matches,\n                    \"count\": len(matches)\n                })\n        \n        return pii_found\n    \n    def _get_pii_type(self, pattern: str) -> str:\n        \"\"\"Get PII type from pattern\"\"\"\n        if \"SSN\" in pattern or \"\\d{3}-\\d{2}-\\d{4}\" in pattern:\n            return \"SSN\"\n        elif \"credit\" in pattern or \"\\d{4}\" in pattern:\n            return \"Credit Card\"\n        elif \"@\" in pattern:\n            return \"Email\"\n        return \"Unknown\"\n    \n    def filter_response(self, text: str) -> Dict:\n        \"\"\"Comprehensive safety check\"\"\"\n        toxicity = self.check_toxicity(text)\n        pii = self.detect_pii(text)\n        \n        is_safe = not toxicity[\"is_toxic\"] and len(pii) == 0\n        \n        return {\n            \"is_safe\": is_safe,\n            \"toxicity\": toxicity,\n            \"pii\": pii,\n            \"filtered_text\": self._redact_pii(text, pii) if pii else text\n        }\n    \n    def _redact_pii(self, text: str, pii_list: List[Dict]) -> str:\n        \"\"\"Redact PII from text\"\"\"\n        filtered = text\n        for pii_item in pii_list:\n            for match in pii_item[\"matches\"]:\n                filtered = filtered.replace(match, \"[REDACTED]\")\n        return filtered\n\n# Example usage\nfilter = SafetyFilter()\ntest_text = \"Contact me at john.doe@example.com or call 555-1234\"\n\nresult = filter.filter_response(test_text)\nprint(\"Safety Filter Results:\")\nprint(f\"  Safe: {result['is_safe']}\")\nprint(f\"  PII detected: {len(result['pii'])}\")\nprint(f\"  Filtered text: {result['filtered_text']}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n\u2705 **Module Complete**\n\n## Next Steps\n\nContinue to the next module in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}