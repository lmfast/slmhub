{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.4: Complete Transformer Block\n\n**Goal**: Build a complete SmolLM-135M transformer layer\n\n**Time**: 60 minutes\n\n**Concepts Covered**:\n- SmolLM-135M architecture (9 layers, 576 hidden, 9 heads, 1536 FFN)\n- Complete transformer layer implementation\n- Forward pass with real tokens\n- Component profiling (time/memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install torch numpy matplotlib seaborn transformers -q"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport time\n\ntorch.manual_seed(42)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Complete Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# SmolLM-135M specs\nd_model = 576\nn_heads = 9\nd_ff = 1536\nn_layers = 9\nvocab_size = 32000\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, d_model, n_heads, d_ff):\n        super().__init__()\n        # Multi-head attention\n        self.attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n        # FFN with SwiGLU\n        self.ffn = nn.Sequential(\n            nn.Linear(d_model, d_ff * 2),\n            nn.SiLU(),\n            nn.Linear(d_ff, d_model)\n        )\n        # Normalization\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n    \n    def forward(self, x):\n        # Pre-norm architecture\n        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n        # FFN\n        x1, x2 = self.ffn[0](x).chunk(2, dim=-1)\n        x = x + self.ffn[2](F.silu(x1) * x2)\n        return x\n\nblock = TransformerBlock(d_model, n_heads, d_ff)\nprint(f\"Parameters: {sum(p.numel() for p in block.parameters()) / 1e6:.2f}M\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n\n\u2705 **Module Complete**\n\n## Next Steps\n\nContinue to the next module in the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}