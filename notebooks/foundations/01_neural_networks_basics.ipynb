{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module 1.1: Neural Networks - The Basics\n",
        "\n",
        "**Goal**: Understand how information flows through networks\n",
        "\n",
        "**Time**: 60 minutes\n",
        "\n",
        "**Concepts Covered**:\n",
        "- Forward pass visualization\n",
        "- Loss calculation\n",
        "- Backward pass (gradients)\n",
        "- Single-head attention\n",
        "- Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Install required packages (run once)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!pip install torch numpy matplotlib seaborn -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 1: Build Your First Neural Network (15 mins)\n",
        "\n",
        "We'll build a simple 2-layer network from scratch to learn the XOR function.\n",
        "\n",
        "**XOR Truth Table**:\n",
        "```\n",
        "Input1  Input2  Output\n",
        "  0       0       0\n",
        "  0       1       1\n",
        "  1       0       1\n",
        "  1       1       0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# XOR dataset\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "print(\"Input shape:\", X.shape)\n",
        "print(\"Output shape:\", y.shape)\n",
        "print(\"\\nDataset:\")\n",
        "for i in range(len(X)):\n",
        "    print(f\"  {X[i].numpy()} -> {y[i].item()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    \"\"\"Simple 2-layer neural network\n",
        "    \n",
        "    Architecture: Input(2) -> Hidden(4) -> Output(1)\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=2, hidden_size=4, output_size=1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Forward pass with visualization\n",
        "        hidden = torch.sigmoid(self.fc1(x))  # Hidden layer with sigmoid activation\n",
        "        output = torch.sigmoid(self.fc2(hidden))  # Output layer\n",
        "        return output, hidden  # Return both for visualization\n",
        "\n",
        "# Initialize model\n",
        "model = SimpleNN()\n",
        "print(\"Model architecture:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters())}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Training setup\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "# Track loss history\n",
        "losses = []\n",
        "\n",
        "# Training loop\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    predictions, hidden = model(X)\n",
        "    loss = criterion(predictions, y)\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Track loss\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize learning curve\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Network Learning XOR Function')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Test the trained model\n",
        "print(\"\\nFinal predictions:\")\n",
        "with torch.no_grad():\n",
        "    predictions, hidden_states = model(X)\n",
        "    for i in range(len(X)):\n",
        "        print(f\"  Input: {X[i].numpy()} -> Predicted: {predictions[i].item():.4f}, True: {y[i].item()}\")\n",
        "\n",
        "# Enhanced XOR visualization: Decision boundary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Enhanced Visualization: Decision Boundary\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create a grid of points\n",
        "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 100), np.linspace(-0.5, 1.5, 100))\n",
        "grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    grid_pred, _ = model(grid_points)\n",
        "    grid_pred = grid_pred.numpy().reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "plt.figure(figsize=(10, 8))\n",
        "contour = plt.contourf(xx, yy, grid_pred, levels=20, cmap='RdYlBu', alpha=0.6)\n",
        "plt.colorbar(contour, label='Model Output')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y.squeeze(), s=200, cmap='RdYlBu', edgecolors='black', linewidths=2, zorder=5)\n",
        "plt.xlabel('Input 1')\n",
        "plt.ylabel('Input 2')\n",
        "plt.title('XOR Decision Boundary Visualization')\n",
        "plt.grid(True, alpha=0.3)\n",
        "for i, (x_val, y_val) in enumerate(X):\n",
        "    plt.annotate(f'({int(x_val[0])},{int(x_val[1])})', (x_val[0], x_val[1]), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 2: Attention is All You Need - Visual Proof (20 mins)\n",
        "\n",
        "Implement single-head attention from scratch and visualize how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def single_head_attention(Q, K, V, mask=None):\n",
        "    \"\"\"\n",
        "    Scaled Dot-Product Attention\n",
        "    \n",
        "    Args:\n",
        "        Q: Query matrix (batch, seq_len, d_k)\n",
        "        K: Key matrix (batch, seq_len, d_k)\n",
        "        V: Value matrix (batch, seq_len, d_v)\n",
        "        mask: Optional mask (batch, seq_len, seq_len)\n",
        "    \n",
        "    Returns:\n",
        "        output: Attention output (batch, seq_len, d_v)\n",
        "        attention_weights: Attention weights (batch, seq_len, seq_len)\n",
        "    \"\"\"\n",
        "    d_k = Q.size(-1)\n",
        "    \n",
        "    # Step 1: Compute attention scores (Q @ K^T)\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1))\n",
        "    \n",
        "    # Step 2: Scale by sqrt(d_k)\n",
        "    scores = scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "    \n",
        "    # Step 3: Apply mask if provided\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    \n",
        "    # Step 4: Apply softmax\n",
        "    attention_weights = F.softmax(scores, dim=-1)\n",
        "    \n",
        "    # Step 5: Weighted sum of values\n",
        "    output = torch.matmul(attention_weights, V)\n",
        "    \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Example sentence: \"The cat sat on the mat\"\n",
        "sentence = \"The cat sat on the mat\"\n",
        "tokens = sentence.split()\n",
        "seq_len = len(tokens)\n",
        "d_model = 8  # Small dimension for visualization\n",
        "\n",
        "# Create random embeddings for tokens\n",
        "torch.manual_seed(42)\n",
        "embeddings = torch.randn(1, seq_len, d_model)\n",
        "\n",
        "# Create Q, K, V matrices (in practice, these are learned projections)\n",
        "Q = embeddings\n",
        "K = embeddings\n",
        "V = embeddings\n",
        "\n",
        "# Compute attention\n",
        "output, attention_weights = single_head_attention(Q, K, V)\n",
        "\n",
        "print(f\"Input shape: {embeddings.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Attention weights shape: {attention_weights.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize attention heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    attention_weights[0].detach().numpy(),\n",
        "    xticklabels=tokens,\n",
        "    yticklabels=tokens,\n",
        "    cmap='YlOrRd',\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cbar_kws={'label': 'Attention Weight'},\n",
        "    linewidths=0.5\n",
        ")\n",
        "plt.title('Single-Head Attention Heatmap\\n\"The cat sat on the mat\"', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Key (attending to)', fontsize=12)\n",
        "plt.ylabel('Query (attending from)', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"- Each row shows what a token attends to\")\n",
        "print(\"- Brighter colors = higher attention\")\n",
        "print(\"- Diagonal is often bright (self-attention)\")\n",
        "print(\"- Off-diagonal patterns show relationships (e.g., 'cat' â†’ 'sat')\")\n",
        "\n",
        "# Additional example: Show attention for different sentence structures\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Additional Example: Subject-Verb Relationship\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "sentence2 = \"The dog chased the ball\"\n",
        "tokens2 = sentence2.split()\n",
        "seq_len2 = len(tokens2)\n",
        "embeddings2 = torch.randn(1, seq_len2, d_model)\n",
        "Q2, K2, V2 = embeddings2, embeddings2, embeddings2\n",
        "output2, attn2 = single_head_attention(Q2, K2, V2)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    attn2[0].detach().numpy(),\n",
        "    xticklabels=tokens2,\n",
        "    yticklabels=tokens2,\n",
        "    cmap='YlOrRd',\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cbar_kws={'label': 'Attention Weight'},\n",
        "    linewidths=0.5\n",
        ")\n",
        "plt.title('Attention: \"The dog chased the ball\"\\n(Notice subject-verb relationships)', \n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Key (attending to)', fontsize=12)\n",
        "plt.ylabel('Query (attending from)', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lesson 3: Multi-Head Attention (25 mins)\n",
        "\n",
        "Scale to 8 attention heads to capture different relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "        \n",
        "        # Linear projections for Q, K, V\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def split_heads(self, x):\n",
        "        \"\"\"Split into multiple heads\"\"\"\n",
        "        batch_size, seq_len, d_model = x.size()\n",
        "        return x.view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
        "    \n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, d_model = x.size()\n",
        "        \n",
        "        # Linear projections\n",
        "        Q = self.W_q(x)\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "        \n",
        "        # Split into heads\n",
        "        Q = self.split_heads(Q)  # (batch, num_heads, seq_len, d_k)\n",
        "        K = self.split_heads(K)\n",
        "        V = self.split_heads(V)\n",
        "        \n",
        "        # Compute attention for each head\n",
        "        d_k = Q.size(-1)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
        "        \n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        \n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        output = torch.matmul(attention_weights, V)\n",
        "        \n",
        "        # Concatenate heads\n",
        "        output = output.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n",
        "        \n",
        "        # Final linear projection\n",
        "        output = self.W_o(output)\n",
        "        \n",
        "        return output, attention_weights\n",
        "\n",
        "# Initialize multi-head attention\n",
        "d_model = 64\n",
        "num_heads = 8\n",
        "mha = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "# Create input\n",
        "batch_size = 1\n",
        "seq_len = 6\n",
        "x = torch.randn(batch_size, seq_len, d_model)\n",
        "\n",
        "# Forward pass\n",
        "output, attention_weights = mha(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Attention weights shape: {attention_weights.shape}\")\n",
        "print(f\"  (batch, num_heads, seq_len, seq_len)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize all 8 attention heads\n",
        "fig, axes = plt.subplots(2, 4, figsize=(18, 9))\n",
        "axes = axes.flatten()\n",
        "\n",
        "tokens = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "\n",
        "for head in range(num_heads):\n",
        "    attn_matrix = attention_weights[0, head].detach().numpy()\n",
        "    sns.heatmap(\n",
        "        attn_matrix,\n",
        "        xticklabels=tokens,\n",
        "        yticklabels=tokens,\n",
        "        cmap='YlOrRd',\n",
        "        ax=axes[head],\n",
        "        cbar=True,\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        annot=True,\n",
        "        fmt='.2f',\n",
        "        cbar_kws={'label': 'Weight'}\n",
        "    )\n",
        "    axes[head].set_title(f'Head {head + 1}', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Multi-Head Attention (8 Heads) - \"The cat sat on the mat\"', \n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸŽ¯ EXERCISE: Identify Head Specializations\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAnalyze the attention patterns above and identify which heads focus on:\")\n",
        "print(\"\\n1. SYNTAX (Grammatical relationships):\")\n",
        "print(\"   - Article-noun: 'The' â†’ 'cat', 'the' â†’ 'mat'\")\n",
        "print(\"   - Preposition-object: 'on' â†’ 'mat'\")\n",
        "print(\"\\n2. SEMANTICS (Meaning relationships):\")\n",
        "print(\"   - Subject-verb: 'cat' â†’ 'sat'\")\n",
        "print(\"   - Verb-object: 'sat' â†’ 'on'\")\n",
        "print(\"\\n3. POSITION (Spatial relationships):\")\n",
        "print(\"   - Neighboring tokens (adjacent positions)\")\n",
        "print(\"   - Long-range dependencies\")\n",
        "print(\"\\n4. SELF-ATTENTION:\")\n",
        "print(\"   - Strong diagonal patterns (token attending to itself)\")\n",
        "print(\"\\nðŸ’¡ Tip: Look for patterns where attention weights are consistently high\")\n",
        "print(\"   between specific token pairs across different query positions.\")\n",
        "print(\"\\n\" + \"-\"*60)\n",
        "print(\"Write your observations:\")\n",
        "print(\"  Syntax-focused heads: _____\")\n",
        "print(\"  Semantics-focused heads: _____\")\n",
        "print(\"  Position-focused heads: _____\")\n",
        "print(\"-\"*60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "âœ… **Neural Networks**: Information flows forward, gradients flow backward\n",
        "\n",
        "âœ… **Attention Mechanism**: Allows tokens to \"look at\" other tokens\n",
        "\n",
        "âœ… **Multi-Head Attention**: Multiple perspectives capture different relationships\n",
        "\n",
        "âœ… **Scaled Dot-Product**: Division by âˆšd_k prevents gradient vanishing\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Continue to **Module 1.2: Transformer Architecture Deep Dive** to learn about:\n",
        "- Position encoding (sinusoidal and RoPE)\n",
        "- Feed-forward networks\n",
        "- Layer normalization\n",
        "- Complete transformer blocks"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}