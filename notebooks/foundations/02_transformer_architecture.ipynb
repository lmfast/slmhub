{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1.2: Transformer Architecture Deep Dive\n",
    "\n",
    "**Goal**: Understand position encoding, RoPE, and core transformer components\n",
    "\n",
    "**Time**: 50 minutes\n",
    "\n",
    "**Concepts Covered**:\n",
    "- Sinusoidal position encoding\n",
    "- Rotary Position Embedding (RoPE)\n",
    "- 2D/3D position embedding visualization\n",
    "- RoPE vs absolute encoding comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: Sinusoidal Position Encoding (15 mins)\n",
    "\n",
    "The original Transformer uses fixed sinusoidal position encodings to inject positional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_position_encoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Generate sinusoidal position encodings\n",
    "    \n",
    "    Args:\n",
    "        seq_len: Sequence length\n",
    "        d_model: Model dimension\n",
    "    \n",
    "    Returns:\n",
    "        pos_encoding: (seq_len, d_model) tensor\n",
    "    \"\"\"\n",
    "    pos_encoding = np.zeros((seq_len, d_model))\n",
    "    \n",
    "    for pos in range(seq_len):\n",
    "        for i in range(0, d_model, 2):\n",
    "            # Even indices: sin\n",
    "            pos_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "            # Odd indices: cos\n",
    "            if i + 1 < d_model:\n",
    "                pos_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * (i + 1)) / d_model)))\n",
    "    \n",
    "    return torch.tensor(pos_encoding, dtype=torch.float32)\n",
    "\n",
    "# Generate position encodings\n",
    "seq_len = 50\n",
    "d_model = 128\n",
    "pos_enc = sinusoidal_position_encoding(seq_len, d_model)\n",
    "\n",
    "print(f\"Position encoding shape: {pos_enc.shape}\")\n",
    "print(f\"First position: {pos_enc[0, :5]}\")\n",
    "print(f\"Last position: {pos_enc[-1, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize position encoding heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(\n",
    "    pos_enc.numpy()[:, :64].T,  # Show first 64 dimensions\n",
    "    cmap='RdYlBu',\n",
    "    cbar_kws={'label': 'Encoding Value'},\n",
    "    xticklabels=10,\n",
    "    yticklabels=10\n",
    ")\n",
    "plt.xlabel('Position in Sequence')\n",
    "plt.ylabel('Dimension')\n",
    "plt.title('Sinusoidal Position Encoding Heatmap', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Each row is a dimension, each column is a position\")\n",
    "print(\"- Patterns repeat at different frequencies\")\n",
    "print(\"- Lower dimensions change slowly, higher dimensions change rapidly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2: Rotary Position Embedding (RoPE) (20 mins)\n",
    "\n",
    "RoPE rotates query and key vectors by their position, enabling relative position awareness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rope(x, freqs_cis):\n",
    "    \"\"\"\n",
    "    Apply Rotary Position Embedding (RoPE) to input tensor\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor (..., seq_len, d_model)\n",
    "        freqs_cis: Precomputed frequency cis values (seq_len, d_model // 2, 2)\n",
    "    \n",
    "    Returns:\n",
    "        Rotated tensor\n",
    "    \"\"\"\n",
    "    # Reshape to separate real and imaginary parts\n",
    "    x_reshaped = x.float().reshape(*x.shape[:-1], -1, 2)\n",
    "    \n",
    "    # Convert to complex numbers\n",
    "    x_complex = torch.view_as_complex(x_reshaped)\n",
    "    \n",
    "    # Apply rotation (complex multiplication)\n",
    "    freqs_cis_complex = torch.view_as_complex(freqs_cis)\n",
    "    x_rotated = x_complex * freqs_cis_complex\n",
    "    \n",
    "    # Convert back to real\n",
    "    x_out = torch.view_as_real(x_rotated)\n",
    "    return x_out.flatten(-2)\n",
    "\n",
    "def precompute_freqs_cis(dim, end, theta=10000.0):\n",
    "    \"\"\"\n",
    "    Precompute frequency cis values for RoPE\n",
    "    \n",
    "    Args:\n",
    "        dim: Model dimension (must be even)\n",
    "        end: Maximum sequence length\n",
    "        theta: Base frequency\n",
    "    \n",
    "    Returns:\n",
    "        freqs_cis: (end, dim // 2, 2) tensor\n",
    "    \"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2).float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)\n",
    "    freqs = torch.outer(t, freqs)\n",
    "    \n",
    "    # Convert to complex exponential form: e^(i*theta) = cos(theta) + i*sin(theta)\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    \n",
    "    return torch.view_as_real(freqs_cis)\n",
    "\n",
    "# Precompute RoPE frequencies\n",
    "d_model = 64\n",
    "seq_len = 32\n",
    "freqs_cis = precompute_freqs_cis(d_model, seq_len)\n",
    "\n",
    "print(f\"RoPE frequencies shape: {freqs_cis.shape}\")\n",
    "print(f\"First position frequencies (first 4 dims): {freqs_cis[0, :2, :]}\")\n",
    "print(f\"Last position frequencies (first 4 dims): {freqs_cis[-1, :2, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RoPE rotation in 2D\n",
    "def visualize_rope_2d():\n",
    "    \"\"\"Visualize how RoPE rotates vectors in 2D space\"\"\"\n",
    "    # Create a simple 2D vector\n",
    "    vec = torch.tensor([1.0, 0.0])\n",
    "    \n",
    "    # Create 2D RoPE frequencies\n",
    "    dim = 2\n",
    "    positions = torch.arange(0, 8)\n",
    "    freqs = 1.0 / (10000.0 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    for pos in positions:\n",
    "        angle = pos * freqs[0]\n",
    "        rotated_x = vec[0] * np.cos(angle) - vec[1] * np.sin(angle)\n",
    "        rotated_y = vec[0] * np.sin(angle) + vec[1] * np.cos(angle)\n",
    "        \n",
    "        ax.arrow(0, 0, rotated_x, rotated_y, head_width=0.1, head_length=0.1, \n",
    "                fc='blue', ec='blue', alpha=0.6, length_includes_head=True)\n",
    "        ax.text(rotated_x * 1.2, rotated_y * 1.2, f'P{pos.item()}', fontsize=10)\n",
    "    \n",
    "    ax.set_xlim(-1.5, 1.5)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('Dimension 0')\n",
    "    ax.set_ylabel('Dimension 1')\n",
    "    ax.set_title('RoPE Rotation Visualization\\n(Vector rotated by position)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_rope_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D visualization of position embeddings\n",
    "def visualize_3d_embeddings():\n",
    "    \"\"\"Visualize position embeddings in 3D space\"\"\"\n",
    "    # Use PCA to reduce to 3D for visualization\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    # Generate sinusoidal embeddings\n",
    "    pos_enc = sinusoidal_position_encoding(seq_len=20, d_model=64)\n",
    "    \n",
    "    # Reduce to 3D\n",
    "    pca = PCA(n_components=3)\n",
    "    pos_3d = pca.fit_transform(pos_enc.numpy())\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Plot positions\n",
    "    scatter = ax.scatter(pos_3d[:, 0], pos_3d[:, 1], pos_3d[:, 2], \n",
    "                        c=range(len(pos_3d)), cmap='viridis', s=100)\n",
    "    \n",
    "    # Connect sequential positions\n",
    "    for i in range(len(pos_3d) - 1):\n",
    "        ax.plot([pos_3d[i, 0], pos_3d[i+1, 0]], \n",
    "                [pos_3d[i, 1], pos_3d[i+1, 1]], \n",
    "                [pos_3d[i, 2], pos_3d[i+1, 2]], \n",
    "                'gray', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title('3D Position Embedding Space\\n(First 20 positions)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=ax, label='Position')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    !pip install scikit-learn -q\n",
    "    visualize_3d_embeddings()\n",
    "except:\n",
    "    print(\"Skipping 3D visualization (scikit-learn not available)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3: RoPE vs Absolute Encoding Benchmark (15 mins)\n",
    "\n",
    "Compare RoPE and absolute position encoding on a simple task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbsolutePositionEncoding(nn.Module):\n",
    "    \"\"\"Absolute position encoding (additive)\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = sinusoidal_position_encoding(max_len, d_model)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1), :]\n",
    "\n",
    "class RoPEPositionEncoding(nn.Module):\n",
    "    \"\"\"Rotary Position Embedding\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        freqs_cis = precompute_freqs_cis(d_model, max_len)\n",
    "        self.register_buffer('freqs_cis', freqs_cis)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply RoPE to queries and keys (simplified: apply to x)\n",
    "        return apply_rope(x, self.freqs_cis[:x.size(1)])\n",
    "\n",
    "# Simple attention with position encoding\n",
    "def attention_with_pos(x, pos_encoder, use_rope=False):\n",
    "    \"\"\"Compute attention with position encoding\"\"\"\n",
    "    if use_rope:\n",
    "        # For RoPE, we apply to Q and K separately\n",
    "        q = pos_encoder(x)\n",
    "        k = pos_encoder(x)\n",
    "    else:\n",
    "        # For absolute, add to embeddings\n",
    "        x_pos = pos_encoder(x)\n",
    "        q = k = x_pos\n",
    "    \n",
    "    # Compute attention\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(x.size(-1))\n",
    "    attn = torch.softmax(scores, dim=-1)\n",
    "    return torch.matmul(attn, x), attn\n",
    "\n",
    "# Test on sequence\n",
    "d_model = 32\n",
    "seq_len = 16\n",
    "batch_size = 1\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "# Absolute encoding\n",
    "abs_encoder = AbsolutePositionEncoding(d_model, seq_len)\n",
    "out_abs, attn_abs = attention_with_pos(x, abs_encoder, use_rope=False)\n",
    "\n",
    "# RoPE encoding\n",
    "rope_encoder = RoPEPositionEncoding(d_model, seq_len)\n",
    "out_rope, attn_rope = attention_with_pos(x, rope_encoder, use_rope=True)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Absolute encoding output shape: {out_abs.shape}\")\n",
    "print(f\"RoPE output shape: {out_rope.shape}\")\n",
    "print(f\"\\nAbsolute attention shape: {attn_abs.shape}\")\n",
    "print(f\"RoPE attention shape: {attn_rope.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare attention patterns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(attn_abs[0].detach().numpy(), ax=axes[0], cmap='YlOrRd', cbar=True)\n",
    "axes[0].set_title('Absolute Position Encoding\\nAttention Pattern', fontweight='bold')\n",
    "axes[0].set_xlabel('Key Position')\n",
    "axes[0].set_ylabel('Query Position')\n",
    "\n",
    "sns.heatmap(attn_rope[0].detach().numpy(), ax=axes[1], cmap='YlOrRd', cbar=True)\n",
    "axes[1].set_title('RoPE Position Encoding\\nAttention Pattern', fontweight='bold')\n",
    "axes[1].set_xlabel('Key Position')\n",
    "axes[1].set_ylabel('Query Position')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Differences:\")\n",
    "print(\"- Absolute: Fixed patterns based on absolute positions\")\n",
    "print(\"- RoPE: Relative position awareness, better for variable-length sequences\")\n",
    "print(\"- RoPE: More efficient (no addition, just rotation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "✅ **Position Encoding**: Injects positional information into token embeddings\n",
    "\n",
    "✅ **Sinusoidal Encoding**: Fixed, additive encoding used in original Transformer\n",
    "\n",
    "✅ **RoPE**: Rotates query/key vectors by position, enabling relative position awareness\n",
    "\n",
    "✅ **RoPE Advantages**: Better extrapolation, more efficient, relative position awareness\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Module 1.3: Feed-Forward Networks & Normalization** to learn about:\n",
    "- SwiGLU activation functions\n",
    "- LayerNorm vs RMSNorm\n",
    "- Memory profiling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
