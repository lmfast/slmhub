{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Prompt Engineering for SLMs\n",
                "\n",
                "This notebook demonstrates effective prompting strategies for Small Language Models, corresponding to the SLM Hub [Prompting Guide](https://slmhub.gitbook.io/slmhub/docs/learn/fundamentals/prompting).\n",
                "\n",
                "## 1. Setup\n",
                "We use Ollama or Transformers. For this Colab, we'll use `transformers` to run a small model if you don't have Ollama running."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install transformers accelerate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load Model\n",
                "Loading `Phi-3-mini-4k-instruct`, a very capable SLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "import torch\n",
                "\n",
                "pipe = pipeline(\n",
                "    \"text-generation\",\n",
                "    model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
                "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
                "    device_map=\"auto\",\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Basic vs. Structured Prompts\n",
                "SLMs need more structure than LLMs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate(prompt):\n",
                "    messages = [\n",
                "        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
                "        {\"role\": \"user\", \"content\": prompt},\n",
                "    ]\n",
                "    outputs = pipe(messages, max_new_tokens=128)\n",
                "    return outputs[0][\"generated_text\"][-1][\"content\"]\n",
                "\n",
                "# Bad Prompt\n",
                "print(\"--- Weak Prompt ---\")\n",
                "print(generate(\"Fix this code: def add(a,b): return a-b\"))\n",
                "\n",
                "# Good Prompt (Structured)\n",
                "print(\"\\n--- Strong Prompt ---\")\n",
                "strong_prompt = \"\"\"\n",
                "Role: Python Expert\n",
                "Task: Debug the following function.\n",
                "Code:\n",
                "def add(a,b): return a-b\n",
                "\n",
                "format:\n",
                "1. Identify the bug\n",
                "2. Provide fixed code\n",
                "\"\"\"\n",
                "print(generate(strong_prompt))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Chain of Thought\n",
                "Asking the model to think step-by-step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cot_prompt = \"\"\"\n",
                "Solve this logic puzzle: \n",
                "I have 3 apples. I eat one. I buy two more strings of bananas. How many apples do I have?\n",
                "\n",
                "Think step by step.\n",
                "\"\"\"\n",
                "print(generate(cot_prompt))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}