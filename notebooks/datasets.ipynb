{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Dataset Curation: Deduplication & Quality Filtering\n",
                "\n",
                "This notebook demonstrates key data curation techniques used for training SLMs, corresponding to the SLM Hub [Dataset Guide](https://slmhub.gitbook.io/slmhub/docs/learn/concepts/datasets).\n",
                "\n",
                "## 1. Setup\n",
                "Install `datasketch` for MinHash deduplication."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install datasketch"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Deduplication (MinHash)\n",
                "Detect near-duplicate documents to clean your training data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasketch import MinHash\n",
                "\n",
                "def get_minhash(text, num_perm=128):\n",
                "    m = MinHash(num_perm=num_perm)\n",
                "    for word in text.split():\n",
                "        m.update(word.encode('utf8'))\n",
                "    return m\n",
                "\n",
                "docs = [\n",
                "    \"The quick brown fox jumps over the lazy dog.\",\n",
                "    \"The quick brown fox jumps over the lazy dog.\", # Exact duplicate\n",
                "    \"The fast brown fox jumps over the lazy dog.\",  # Near duplicate\n",
                "    \"Machine learning is fascinating.\"\n",
                "]\n",
                "\n",
                "unique_hashes = set()\n",
                "unique_docs = []\n",
                "\n",
                "print(\"Processing documents...\")\n",
                "for doc in docs:\n",
                "    m = get_minhash(doc)\n",
                "    # In real pipeline, use LSH (Locality Sensitive Hashing) for efficiency\n",
                "    # Here simple hash comparison for exact/near detection logic would be more complex\n",
                "    # For this demo, we check exact MinHash match (which implies strong similarity)\n",
                "    \n",
                "    # Simply digest for exact dedup of hash signature\n",
                "    signature = tuple(m.digest())\n",
                "    \n",
                "    if signature not in unique_hashes:\n",
                "        unique_hashes.add(signature)\n",
                "        unique_docs.append(doc)\n",
                "        print(f\"Keep: '{doc}'\")\n",
                "    else:\n",
                "        print(f\"Drop: '{doc}' (Duplicate)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Heuristic Quality Filtering\n",
                "Simple rules to remove low-quality text."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def quality_check(text):\n",
                "    words = text.split()\n",
                "    if len(words) < 5:\n",
                "        return False, \"Too short\"\n",
                "    \n",
                "    # Check for symbol ratio (spam/code noise)\n",
                "    alnum_count = sum(c.isalnum() for c in text)\n",
                "    if alnum_count / len(text) < 0.7:\n",
                "        return False, \"Too many symbols\"\n",
                "        \n",
                "    return True, \"Pass\"\n",
                "\n",
                "examples = [\n",
                "    \"Valid sentence for training.\",\n",
                "    \"Hi\",\n",
                "    \"$$$ @@@ ### ...\"\n",
                "]\n",
                "\n",
                "print(\"\\nQuality Check:\")\n",
                "for ex in examples:\n",
                "    passed, reason = quality_check(ex)\n",
                "    print(f\"'{ex}' -> {reason}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}