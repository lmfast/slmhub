---
title: Fundamentals
description: "Core concepts you'll use repeatedly: tokenization, quantization, fine-tuning, prompting."
---

# Fundamentals

Master the essential building blocks of working with Small Language Models. These concepts apply whether you're deploying locally, fine-tuning for your use case, or optimizing for edge devices.

## Start Here

If you're new to SLMs, begin with these two critical topics:

- **[Quantization](/slmhub/docs/learn/fundamentals/quantization/)** - Understand how to make models smaller and fit them on your hardware (answers most "why doesn't it fit?" questions)
- **[Fine-tuning](/slmhub/docs/learn/fundamentals/fine-tuning/)** - Learn how to adapt models to your specific needs (answers most "how do I customize?" questions)

## All Fundamentals

Explore all fundamental concepts:

- **[GenAI Basics](/slmhub/docs/learn/fundamentals/genai-basics/)** - Understanding Generative AI and how it works
- **[Tokenization](/slmhub/docs/learn/fundamentals/tokenization/)** - How text becomes numbers that models understand
- **[Architecture](/slmhub/docs/learn/fundamentals/architecture/)** - Inside the transformer: how SLMs actually work
- **[Embeddings](/slmhub/docs/learn/fundamentals/embeddings/)** - Vector representations and semantic similarity
- **[Prompting for SLMs](/slmhub/docs/learn/fundamentals/prompting-for-slms/)** - Effective prompting strategies for smaller models
